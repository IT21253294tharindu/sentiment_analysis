{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9388bca-5727-4f44-8646-b1571aee0e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface_hub\n",
      "  Using cached huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pandas in f:\\projects\\github projects\\sentiment_analysis\\env\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: tqdm in f:\\projects\\github projects\\sentiment_analysis\\env\\lib\\site-packages (4.66.6)\n",
      "Collecting filelock (from huggingface_hub)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub)\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in f:\\projects\\github projects\\sentiment_analysis\\env\\lib\\site-packages (from huggingface_hub) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in f:\\projects\\github projects\\sentiment_analysis\\env\\lib\\site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in f:\\projects\\github projects\\sentiment_analysis\\env\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface_hub)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in f:\\projects\\github projects\\sentiment_analysis\\env\\lib\\site-packages (from pandas) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in f:\\projects\\github projects\\sentiment_analysis\\env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in f:\\projects\\github projects\\sentiment_analysis\\env\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in f:\\projects\\github projects\\sentiment_analysis\\env\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: colorama in f:\\projects\\github projects\\sentiment_analysis\\env\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in f:\\projects\\github projects\\sentiment_analysis\\env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in f:\\projects\\github projects\\sentiment_analysis\\env\\lib\\site-packages (from requests->huggingface_hub) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in f:\\projects\\github projects\\sentiment_analysis\\env\\lib\\site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\projects\\github projects\\sentiment_analysis\\env\\lib\\site-packages (from requests->huggingface_hub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\projects\\github projects\\sentiment_analysis\\env\\lib\\site-packages (from requests->huggingface_hub) (2024.8.30)\n",
      "Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: typing-extensions, fsspec, filelock, huggingface_hub\n",
      "Successfully installed filelock-3.16.1 fsspec-2024.10.0 huggingface_hub-0.26.2 typing-extensions-4.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub pandas tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d1e06bc-4287-4d8a-9b14-c56df0f38f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in f:\\projects\\github projects\\sentiment_analysis\\env\\lib\\site-packages (0.26.2)\n",
      "Requirement already satisfied: filelock in f:\\projects\\github projects\\sentiment_analysis\\env\\lib\\site-packages (from huggingface_hub) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in f:\\projects\\github projects\\sentiment_analysis\\env\\lib\\site-packages (from huggingface_hub) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in f:\\projects\\github projects\\sentiment_analysis\\env\\lib\\site-packages (from huggingface_hub) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in f:\\projects\\github projects\\sentiment_analysis\\env\\lib\\site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in f:\\projects\\github projects\\sentiment_analysis\\env\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in f:\\projects\\github projects\\sentiment_analysis\\env\\lib\\site-packages (from huggingface_hub) (4.66.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in f:\\projects\\github projects\\sentiment_analysis\\env\\lib\\site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: colorama in f:\\projects\\github projects\\sentiment_analysis\\env\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in f:\\projects\\github projects\\sentiment_analysis\\env\\lib\\site-packages (from requests->huggingface_hub) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in f:\\projects\\github projects\\sentiment_analysis\\env\\lib\\site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\projects\\github projects\\sentiment_analysis\\env\\lib\\site-packages (from requests->huggingface_hub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\projects\\github projects\\sentiment_analysis\\env\\lib\\site-packages (from requests->huggingface_hub) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9ca893e7-63b4-4681-a02b-60b696311f27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a41e909a9bf449c09d9d6bb48f594e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Categories:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Sentiments for claim:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Feedbacks:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: (Request ID: EayfCt04NvwAPHLBjS7Fp)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: s4KCxrUCoy-OvduTQWqVl)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: czjS0M1xNcmy19wc5_WiB)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: fQVMGwyj9l4utN0e_Br_E)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: ctS1dla4fFnVyiTLYK_jG)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: NLrO9r70jqrbPcEUboasw)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: MCUDlMYwXTMxhEaOyCGaO)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: VTYB_G86LrHln-PuQmsPr)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: gPJDzo5ZBc7IWS6K4Lpp7)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: bfEo9BOYmbCLUERKWaJRB)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Feedbacks:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: (Request ID: PwXOAo8JGPKoiROsaNRzV)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: j_lFB5HEIwtbrlxwEVyPP)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: thN0wM6X7__-z3-kB2bIm)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: n1WSq059HrlRly-DY7wuN)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: 5aTrR_NYnaGHMtPTkw2E1)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: 8oal7o9sFem9Pw483xH6R)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: tFxQh85gHVWfSxar84ohE)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: 1IWqsxK7rMeM0hiymY4qq)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: Sg-OSx32OlG32WbjRgUAJ)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: VuDMnHWAwrFiIudCTtHXu)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Feedbacks:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: (Request ID: 0gHEc3COLj9KqoPRJzcLA)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: 0SNQIj8vkuRa4pn4QmskG)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: brLvI0zvs7OLcP1Kwhv3h)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: VWutMFWjsCj3pqjx5j0Lz)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: 2OL4WDXvgJmeJjZAh58QY)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: nYiDzkFThjpcOkboPUsov)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: GAvK8rgzn0QWXCC1upcgB)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: IUXUQcj87Gj6_9UaJck8q)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: rksRFwE9hduPgWum_u-R_)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: OFordY9egFlXHxt8n8fAp)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Sentiments for service:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Feedbacks:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: (Request ID: 4wm9s_-MjkD3L9zA8qOGb)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: cwweFQtsHNPUIx70Tu3kz)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: LKVqq-k9IYVre4abDIRMH)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: ms3T-PL1D2CJMqi_IkRB1)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: GKZ_DHTHp3pA2jkiVc18_)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: Rq5P4xK1BVlzXL2A4WhDF)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: jNPukulsnC-xIo-EF51GL)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: ygSsQf_I_CmQjV_F2F2u1)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: 8Kv8YFwiZtXof-g7SYoDo)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: 3thX1dqg6_zmIo0u00VVU)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Feedbacks:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: (Request ID: 8cm2n86hosmzvtypDVN9H)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: 0044KU6zCPyHuT3Pg3TW9)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: d0uy6jl1x-W-qM91NeA6_)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: Dt-BfdXsd3YtRfHeS6WK-)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: ah8UmK28vXaz7bGaP8k4i)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: JKRFSNPbf1QMSoxuB8SVp)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: i2ZgRTtkWgSD6TO4dr9BF)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: 2Xt691t8Jar_CPsuhNRdw)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: fLoDA1qODM8G6DY56_si5)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: oe2nYv6V_5xSAI7VG8oMd)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Feedbacks:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: (Request ID: GP4p2s-0q-KboN0if3k2T)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: 3U6xujmfGkds5Frttj6ZY)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: oDVAGI-xG6GH0XAJaQr1o)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: NyYvLusQLjrHwrxbyQx67)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: mM13PXlUcy1e0SmrIHw2J)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: dWUtdk9dZkCNRRkFxVLJL)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: z-_NoLVebnQRrqKEEdG7_)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: -CyRqnHN0qmhLB3k2OujA)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: 4Ql9MkFGAj1ZGSyvY4puk)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: YNjDDcZbHHYFOM3J2cTbp)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Sentiments for policy:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Feedbacks:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: (Request ID: nqJPSc7XwtAtfsnD1jZw2)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: OFYdq0ejVjd0u1b5LYhQY)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: ieL6GdhsD_2sRWYrurTtr)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: OHXYa1VGItXEp-frr711U)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: tm3tLv1Vqpu0V3oyZpMLR)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: G7BGOsohtZausAe7_YI0M)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: a4okRRqaoTDoCgy8HKPGS)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: 31iT4PQ4GCRlBQa5BHnXs)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: Ot2JVO0zuLPBLU6gdWx_t)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: 15jt7ql1ShDK3h2AUIWMu)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Feedbacks:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: (Request ID: Xts7FdYLvu4CaelkDaLdJ)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: JWzNEm9_mLDeskbayXRVo)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: tMVvTC4lw2VURWF4LMq7-)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: 7OpIXnoCzhp4054gRYxfi)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: i4gMaw6lwftDSPJ1lKs9-)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: yb2Srix75ymwcQKQIXtbb)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: dmLnJqlc5dta5wUGdTr7-)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: zCiV4lmdZCdKHYqQiEK4_)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: PuLgtaus7rVfZl9rqc_Gj)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: 3h6sTmLhTiDN9zBL7uypH)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Feedbacks:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: (Request ID: BRQol61d5BRuQGBGPnWBV)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: xjfEbq6SbIfJ3tH3tsNkf)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: rcnkdwG0waomjhnnTuNkN)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: yERuCYq5N3sqo1VvP-HYx)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: kAGzl0NZyT37LETA_sgYY)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: tCHFTwsY3qzptZXyZq__E)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: ZIeuo2hGwxozn8g8B029a)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: qemAYs9tadzBZZV3pPLYz)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: 3k4DIkzcaGAwDm-JUt_nc)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Error: (Request ID: G50vjMUql_SXSaFwpUz3z)\n",
      "\n",
      "403 Forbidden: None.\n",
      "Cannot access content at: https://api-inference.huggingface.co/models/tiiuae/falcon-180B.\n",
      "Make sure your token has the correct permissions.\n",
      "The model tiiuae/falcon-180B is too large to be loaded automatically (359GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
      "Generated Dataset Preview:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Dataset saved as 'unique_feedback_dataset.csv'.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "# Initialize Hugging Face InferenceClient\n",
    "client = InferenceClient(model=\"tiiuae/falcon-180B\", token=\"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\")\n",
    "\n",
    "# Prompts for feedback generation\n",
    "prompts = {\n",
    "    \"claim\": {\n",
    "        \"positive\": \"Write a detailed and unique positive feedback about a smooth motor insurance claim process.\",\n",
    "        \"negative\": \"Write a detailed and unique negative feedback about delays in the motor insurance claim process.\",\n",
    "        \"neutral\": \"Write a detailed and unique neutral feedback about an ongoing motor insurance claim process.\"\n",
    "    },\n",
    "    \"service\": {\n",
    "        \"positive\": \"Write a detailed and unique positive feedback about excellent customer service at an motor insurance company.\",\n",
    "        \"negative\": \"Write a detailed and unique negative feedback about poor customer service at an motor insurance company.\",\n",
    "        \"neutral\": \"Write a detailed and unique neutral feedback about average customer service.\"\n",
    "    },\n",
    "    \"policy\": {\n",
    "        \"positive\": \"Write a detailed and unique positive feedback about clear and beneficial motor insurance policy terms.\",\n",
    "        \"negative\": \"Write a detailed and unique negative feedback about unclear and unfavorable motor insurance policy terms.\",\n",
    "        \"neutral\": \"Write a detailed neutral feedback about reading and understanding motor insurance policy terms.\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Generate dataset\n",
    "categories = [\"claim\", \"service\", \"policy\"]\n",
    "sentiments = [\"positive\", \"negative\", \"neutral\"]\n",
    "samples_per_combination = 10  # Set a smaller number for testing\n",
    "\n",
    "dataset = []\n",
    "\n",
    "# Generate feedbacks\n",
    "for category in tqdm(categories, desc=\"Processing Categories\"):\n",
    "    for sentiment in tqdm(sentiments, desc=f\"Processing Sentiments for {category}\", leave=False):\n",
    "        prompt = prompts[category][sentiment]\n",
    "        for _ in tqdm(range(samples_per_combination), desc=\"Generating Feedbacks\", leave=False):\n",
    "            try:\n",
    "                response = client.text_generation(prompt, max_new_tokens=100)\n",
    "                feedback = response.strip()  # Response is a plain string\n",
    "                if not feedback:\n",
    "                    feedback = \"Fallback: Unable to generate feedback.\"\n",
    "                print(f\"Generated Feedback: {feedback}\")  # Debug print\n",
    "                dataset.append({\n",
    "                    \"category\": category,\n",
    "                    \"sentiment\": sentiment,\n",
    "                    \"feedback\": feedback\n",
    "                })\n",
    "                time.sleep(1)  # Add delay to avoid rate limiting\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "\n",
    "# Save to CSV\n",
    "print(\"Generated Dataset Preview:\")\n",
    "df = pd.DataFrame(dataset)\n",
    "print(df.head())  # Debug print\n",
    "df.to_csv(\"unique_feedback_dataset.csv\", index=False)\n",
    "print(\"Dataset saved as 'unique_feedback_dataset.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88a3ddbd-da2b-4eed-892f-21c0ba7d3639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='unique_feedback_dataset.csv' target='_blank'>unique_feedback_dataset.csv</a><br>"
      ],
      "text/plain": [
       "F:\\Projects\\github projects\\sentiment_analysis\\notebooks\\unique_feedback_dataset.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "# For CSV file\n",
    "display(FileLink(\"unique_feedback_dataset.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "359cb18a-4957-4b72-8baa-24410d124f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Dataset Preview:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(\"Generated Dataset Preview:\")\n",
    "print(pd.DataFrame(dataset).head())  # Preview the first few rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69a8345-daf9-4673-ae9e-d4d29a4a5b84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
